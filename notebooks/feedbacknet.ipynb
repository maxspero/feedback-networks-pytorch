{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, x_kernel_size, h_kernel_size, stride=1):        \n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        pad_x = math.floor(x_kernel_size/2)        \n",
    "        pad_h = math.floor(h_kernel_size/2)\n",
    "        self.output_size = output_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # input gate\n",
    "        self.conv_i_x = nn.Conv2d(input_size, output_size, x_kernel_size, stride=stride, padding=pad_x)\n",
    "        self.batchnorm_i_x = nn.BatchNorm2d(output_size)\n",
    "        self.conv_i_h = nn.Conv2d(output_size, output_size, h_kernel_size, stride=1, padding=pad_h)\n",
    "        self.batchnorm_i_h = nn.BatchNorm2d(output_size)\n",
    "        \n",
    "        # forget gate\n",
    "        self.conv_f_x = nn.Conv2d(input_size, output_size, x_kernel_size, stride=stride, padding=pad_x)\n",
    "        self.batchnorm_f_x = nn.BatchNorm2d(output_size)\n",
    "        self.conv_f_h = nn.Conv2d(output_size, output_size, h_kernel_size, stride=1, padding=pad_h)\n",
    "        self.batchnorm_f_h = nn.BatchNorm2d(output_size)\n",
    "        # initialize bias to 1 for x forget input\n",
    "        self.conv_f_x.bias.data.fill_(1)\n",
    "        \n",
    "        # cell gate\n",
    "        self.conv_c_x = nn.Conv2d(input_size, output_size, x_kernel_size, stride=stride, padding=pad_x)\n",
    "        self.batchnorm_c_x = nn.BatchNorm2d(output_size)\n",
    "        self.conv_c_h = nn.Conv2d(output_size, output_size, h_kernel_size, stride=1, padding=pad_h)\n",
    "        self.batchnorm_c_h = nn.BatchNorm2d(output_size)\n",
    "\n",
    "        # output gate\n",
    "        self.conv_o_x = nn.Conv2d(input_size, output_size, x_kernel_size, stride=stride, padding=pad_x)\n",
    "        self.batchnorm_o_x = nn.BatchNorm2d(output_size)\n",
    "        self.conv_o_h = nn.Conv2d(output_size, output_size, h_kernel_size, stride=1, padding=pad_h)\n",
    "        self.batchnorm_o_h = nn.BatchNorm2d(output_size)\n",
    "        \n",
    "        self.last_cell = None\n",
    "        self.last_h = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.last_cell is None:\n",
    "            self.last_cell = Variable(torch.zeros(\n",
    "                (x.size(0), self.output_size, int(x.size(2)/self.stride), \n",
    "                 int(x.size(3)/self.stride))\n",
    "            ))\n",
    "        if self.last_h is None:\n",
    "            self.last_h = Variable(torch.zeros(\n",
    "                (x.size(0), self.output_size, int(x.size(2)/self.stride), \n",
    "                 int(x.size(3)/self.stride))\n",
    "            ))\n",
    "        h = self.last_h\n",
    "        c = self.last_cell\n",
    "        \n",
    "        # input gate\n",
    "        input_x = self.batchnorm_i_x(self.conv_i_x(x))\n",
    "        input_h = self.batchnorm_i_h(self.conv_i_h(h))\n",
    "        input_gate = F.sigmoid(input_x + input_h)\n",
    "        \n",
    "        # forget gate\n",
    "        forget_x = self.batchnorm_f_x(self.conv_f_x(x))\n",
    "        forget_h = self.batchnorm_f_h(self.conv_f_h(h))\n",
    "        forget_gate = F.sigmoid(forget_x + forget_h)\n",
    "        \n",
    "        # forget gate\n",
    "        cell_x = self.batchnorm_c_x(self.conv_c_x(x))\n",
    "        cell_h = self.batchnorm_c_h(self.conv_c_h(h))\n",
    "        cell_intermediate = F.tanh(cell_x + cell_h) # g\n",
    "        cell_gate = (forget_gate * c) + (input_gate * cell_intermediate)\n",
    "        \n",
    "        # output gate\n",
    "        output_x = self.batchnorm_o_x(self.conv_o_x(x))\n",
    "        output_h = self.batchnorm_o_h(self.conv_o_h(h))\n",
    "        output_gate = F.sigmoid(output_x + output_h)\n",
    "        \n",
    "        next_h = output_gate * F.tanh(cell_gate)\n",
    "        self.last_cell = cell_gate\n",
    "        self.last_h = next_h\n",
    "        \n",
    "        return next_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_sizes, strides, num_iterations, x_kernel_size, h_kernel_size):\n",
    "        super(FeedbackConvLSTM, self).__init__()\n",
    "        \n",
    "        assert len(output_sizes) == len(strides)\n",
    "        \n",
    "        self.physical_depth = len(output_sizes)\n",
    "        self.num_iterations = num_iterations\n",
    "        self.input_size = input_size\n",
    "        self.output_sizes = output_sizes\n",
    "        self.strides = strides\n",
    "        self.x_kernel_size = x_kernel_size\n",
    "        self.h_kernel_size = h_kernel_size\n",
    "        \n",
    "        self.convlstm_cells = []\n",
    "        for it in range(self.physical_depth):\n",
    "            if it == 0:\n",
    "                inp_size = input_size\n",
    "            else:\n",
    "                inp_size = output_sizes[it-1]\n",
    "            outp_size = output_sizes[it]\n",
    "            stride = strides[it]\n",
    "            \n",
    "            self.convlstm_cells.append(\n",
    "                ConvLSTMCell(inp_size, outp_size, x_kernel_size, h_kernel_size, stride)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # torch.cat? torch.stack?\n",
    "        end_xts = []\n",
    "        for t in range(self.num_iterations):\n",
    "            for d in range(self.physical_depth):\n",
    "                if d == 0:\n",
    "                    x_t = x # x_t^{d-1}\n",
    "                x_t = self.convlstm_cells[d].forward(x_t)\n",
    "            end_xts.append(x_t)\n",
    "        #all_xts = torch.stack(end_xts, dim=0)\n",
    "        #xts = torch.unbind(all_xts, dim=0)\n",
    "        #return all_xts\n",
    "        return end_xts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackNet32(nn.Module):  # 4 physical depth, 8 iterations\n",
    "    def __init__(self):\n",
    "        super(FeedbackNet32, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, 3, 1, 1)\n",
    "        self.batchnorm = nn.BatchNorm2d(16)\n",
    "        self.feedback_conv_lstm = FeedbackConvLSTM(\n",
    "            16, [32, 32, 64, 64], [2, 1, 2, 1], 8, 3, 3\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.linear = nn.Linear(64, 100)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x_all = self.feedback_conv_lstm(x)\n",
    "        x_finished = []\n",
    "        for x_i in x_all:\n",
    "            x_i = F.relu(x_i)\n",
    "            x_i = self.avg_pool(x_i)\n",
    "            x_i = x_i.view(-1, 64)\n",
    "            x_i = self.linear(x_i)\n",
    "            x_finished.append(x_i)\n",
    "        return x_finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "[transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, \n",
    "                                        transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, \n",
    "                                        transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iteration 0: loss=0.036638\n",
      "Running losses:\n",
      "[ 4.5739212   4.57797337  4.57809973  4.57804489  4.58078194  4.58226204\n",
      "  4.58308887  4.58362293]\n",
      "Epoch 0, iteration 10: loss=0.365373\n",
      "Running losses:\n",
      "[ 45.66669703  45.66688061  45.66656113  45.66848183  45.67412376\n",
      "  45.67894936  45.67781687  45.67306566]\n",
      "Epoch 0, iteration 20: loss=0.361352\n",
      "Running losses:\n",
      "[ 45.17797899  45.17975473  45.17394161  45.16795635  45.16808844\n",
      "  45.16553402  45.16149092  45.15750217]\n",
      "Epoch 0, iteration 30: loss=0.351426\n",
      "Running losses:\n",
      "[ 43.92896414  43.93480921  43.93733072  43.9369936   43.9324584\n",
      "  43.92726374  43.91997528  43.9082365 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-23:\n",
      "Process Process-24:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/maxspero/virtualenvs/ml/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/maxspero/virtualenvs/ml/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-f75bc937bf3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mrunning_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/ml/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/ml/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feedback_net = FeedbackNet32()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(feedback_net.parameters())\n",
    "\n",
    "for epoch in range(3):\n",
    "    running_losses = np.zeros(8)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = feedback_net(inputs)\n",
    "        \n",
    "        losses = [criterion(out, labels) for out in outputs]\n",
    "        loss = sum(losses)\n",
    "        \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        running_losses += [l.data[0] for l in losses]\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 10 == 0:\n",
    "            print('Epoch %d, iteration %d: loss=%f' % (epoch, i, running_loss/1000))\n",
    "            print('Running losses:')\n",
    "            print(running_losses)\n",
    "            running_loss = 0.0\n",
    "            running_losses = np.zeros(8)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': feedback_net.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    })\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, checkpoint['epoch']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
